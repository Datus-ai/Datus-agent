# read_semantic_models_and_metrics.py
"""
è¯»å–semantic_modelå’Œmetricsçš„ç¤ºä¾‹è„šæœ¬
è¯¥è„šæœ¬æ¼”ç¤ºäº†å¦‚ä½•ä»å­˜å‚¨ä¸­è¯»å–è¯­ä¹‰æ¨¡å‹å’ŒæŒ‡æ ‡æ•°æ®
"""

import json
from typing import Dict, List, Any
from pathlib import Path

# å‡è®¾æˆ‘ä»¬ä½¿ç”¨ä¸MetricsScreenç›¸åŒçš„å­˜å‚¨ç±»
try:
    from datus.storage.metric.store import SemanticModelStorage, MetricStorage
    from datus.storage.config import StorageConfig
except ImportError:
    # å¦‚æœæ— æ³•å¯¼å…¥å®é™…çš„å­˜å‚¨ç±»ï¼Œæˆ‘ä»¬åˆ›å»ºæ¨¡æ‹Ÿç±»ç”¨äºæ¼”ç¤º
    class SemanticModelStorage:
        def search_all(self, query: str) -> List[Dict]:
            # æ¨¡æ‹Ÿè¿”å›ä¸€äº›ç¤ºä¾‹æ•°æ®
            return [
                {
                    "semantic_model_name": "transactions",
                    "semantic_model_desc": "Transaction data model",
                    "domain": "finance",
                    "catalog_name": "main_catalog",
                    "database_name": "finance_db",
                    "schema_name": "public",
                    "table_name": "transactions",
                    "layer1": "gold",
                    "layer2": "duck",
                    "catalog_database_schema": "gold_duck",
                    "identifiers": json.dumps([
                        {"name": "transaction_id", "type": "primary"}
                    ]),
                    "dimensions": json.dumps([
                        {"name": "date", "type": "date"},
                        {"name": "category", "type": "string"}
                    ]),
                    "measures": json.dumps([
                        {"name": "amount", "agg": "sum"},
                        {"name": "count", "agg": "count"}
                    ])
                },
                {
                    "semantic_model_name": "users",
                    "semantic_model_desc": "User information model",
                    "domain": "user_analytics",
                    "catalog_name": "main_catalog",
                    "database_name": "analytics_db",
                    "schema_name": "public",
                    "table_name": "users",
                    "layer1": "silver",
                    "layer2": "customer",
                    "catalog_database_schema": "silver_customer",
                    "identifiers": json.dumps([
                        {"name": "user_id", "type": "primary"}
                    ]),
                    "dimensions": json.dumps([
                        {"name": "signup_date", "type": "date"},
                        {"name": "country", "type": "string"}
                    ]),
                    "measures": json.dumps([
                        {"name": "user_count", "agg": "count_distinct"}
                    ])
                }
            ]


    class MetricStorage:
        def search_all(self, semantic_model_name: str, select_fields: Any = None):
            # æ¨¡æ‹Ÿè¿”å›æŒ‡æ ‡æ•°æ®
            if semantic_model_name == "transactions":
                # æ¨¡æ‹ŸPyArrow Tableç»“æ„
                class MockTable:
                    def __init__(self):
                        self.num_rows = 2
                        self.schema = type('Schema', (),
                                           {'names': ['name', 'description', 'sql_query', 'constraint']})()

                    def __getitem__(self, key):
                        data = {
                            'name': ['total_amount', 'transaction_count'],
                            'description': ['Total transaction amount', 'Number of transactions'],
                            'sql_query': ['SELECT SUM(amount) FROM transactions', 'SELECT COUNT(*) FROM transactions'],
                            'constraint': ['sum', 'count']
                        }
                        return [type('Value', (), {'as_py': lambda: v})() for v in data[key]]

                return MockTable()
            return None


def read_semantic_models_and_metrics():
    """
    è¯»å–æ‰€æœ‰è¯­ä¹‰æ¨¡å‹å’Œç›¸å…³æŒ‡æ ‡
    """
    print("å¼€å§‹è¯»å–è¯­ä¹‰æ¨¡å‹å’ŒæŒ‡æ ‡æ•°æ®...")

    # åˆå§‹åŒ–å­˜å‚¨
    semantic_model_storage = SemanticModelStorage()
    metric_storage = MetricStorage()

    # è¯»å–æ‰€æœ‰è¯­ä¹‰æ¨¡å‹
    print("\n1. è¯»å–è¯­ä¹‰æ¨¡å‹...")
    semantic_models = semantic_model_storage.search_all("")

    if not semantic_models:
        print("æœªæ‰¾åˆ°ä»»ä½•è¯­ä¹‰æ¨¡å‹")
        return

    print(f"æ‰¾åˆ° {len(semantic_models)} ä¸ªè¯­ä¹‰æ¨¡å‹:")

    # å­˜å‚¨æ‰€æœ‰æ•°æ®çš„å­—å…¸
    all_data = {}

    # éå†æ¯ä¸ªè¯­ä¹‰æ¨¡å‹
    for i, model in enumerate(semantic_models, 1):
        model_name = model.get('semantic_model_name', 'Unknown')
        print(f"\n  {i}. è¯­ä¹‰æ¨¡å‹: {model_name}")

        # æ˜¾ç¤ºè¯­ä¹‰æ¨¡å‹åŸºæœ¬ä¿¡æ¯
        print(f"     æè¿°: {model.get('semantic_model_desc', 'N/A')}")
        print(f"     åŸŸ: {model.get('domain', 'N/A')}")
        print(
            f"     æ•°æ®åº“è¡¨: {model.get('catalog_name', 'N/A')}.{model.get('database_name', 'N/A')}.{model.get('schema_name', 'N/A')}.{model.get('table_name', 'N/A')}")
        print(f"     åˆ†å±‚: {model.get('layer1', 'N/A')}/{model.get('layer2', 'N/A')}")

        # è§£æå¹¶æ˜¾ç¤ºç»“æ„åŒ–ä¿¡æ¯
        try:
            identifiers = json.loads(model.get('identifiers', '[]'))
            dimensions = json.loads(model.get('dimensions', '[]'))
            measures = json.loads(model.get('measures', '[]'))

            print(f"     æ ‡è¯†ç¬¦æ•°é‡: {len(identifiers)}")
            print(f"     ç»´åº¦æ•°é‡: {len(dimensions)}")
            print(f"     åº¦é‡æ•°é‡: {len(measures)}")
        except json.JSONDecodeError:
            print("     æ— æ³•è§£æç»“æ„åŒ–ä¿¡æ¯")

        # ä¸ºè¯¥è¯­ä¹‰æ¨¡å‹è¯»å–æŒ‡æ ‡
        print(f"     è¯»å–æŒ‡æ ‡...")
        metrics_data = []

        try:
            metrics_table = metric_storage.search_all(model_name, select_fields=None)

            if metrics_table and metrics_table.num_rows > 0:
                # è½¬æ¢PyArrow Tableä¸ºå­—å…¸åˆ—è¡¨
                field_names = metrics_table.schema.names
                for j in range(metrics_table.num_rows):
                    row_dict = {}
                    for field_name in field_names:
                        value = metrics_table[field_name][j]
                        # å¤„ç†PyArrowå€¼
                        if hasattr(value, 'as_py'):
                            row_dict[field_name] = value.as_py()
                        else:
                            row_dict[field_name] = value
                    metrics_data.append(row_dict)

                print(f"     æ‰¾åˆ° {len(metrics_data)} ä¸ªæŒ‡æ ‡:")
                for metric in metrics_data:
                    print(f"       - {metric.get('name', 'Unknown')}: {metric.get('description', 'N/A')}")
            else:
                print(f"     æœªæ‰¾åˆ°æŒ‡æ ‡")

        except Exception as e:
            print(f"     è¯»å–æŒ‡æ ‡æ—¶å‡ºé”™: {str(e)}")

        # å°†æ•°æ®å­˜å‚¨åˆ°å­—å…¸ä¸­
        all_data[model_name] = {
            'semantic_model': model,
            'metrics': metrics_data
        }

    # ä¿å­˜æ•°æ®åˆ°æ–‡ä»¶
    output_file = "semantic_models_and_metrics.json"
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(all_data, f, ensure_ascii=False, indent=2)
        print(f"\næ•°æ®å·²ä¿å­˜åˆ° {output_file}")
    except Exception as e:
        print(f"ä¿å­˜æ•°æ®æ—¶å‡ºé”™: {str(e)}")

    return all_data


def display_hierarchical_structure(data: Dict):
    """
    æŒ‰åˆ†å±‚ç»“æ„æ˜¾ç¤ºæ•°æ®
    """
    print("\n" + "=" * 50)
    print("åˆ†å±‚ç»“æ„è§†å›¾")
    print("=" * 50)

    # æŒ‰domainåˆ†ç»„
    domain_groups = {}
    for model_name, model_data in data.items():
        semantic_model = model_data['semantic_model']
        domain = semantic_model.get('domain', 'unknown_domain')

        if domain not in domain_groups:
            domain_groups[domain] = {}

        layer1 = semantic_model.get('layer1', 'default_layer1')
        if layer1 not in domain_groups[domain]:
            domain_groups[domain][layer1] = {}

        layer2 = semantic_model.get('layer2', 'default_layer2')
        if layer2 not in domain_groups[domain][layer1]:
            domain_groups[domain][layer1][layer2] = []

        domain_groups[domain][layer1][layer2].append(model_data)

    # æ˜¾ç¤ºåˆ†å±‚ç»“æ„
    for domain, layer1_groups in domain_groups.items():
        print(f"\nğŸ“ Domain: {domain}")
        for layer1, layer2_groups in layer1_groups.items():
            print(f"  ğŸ“‚ Layer1: {layer1}")
            for layer2, models in layer2_groups.items():
                print(f"    ğŸ“‚ Layer2: {layer2}")
                for model_data in models:
                    semantic_model = model_data['semantic_model']
                    model_name = semantic_model.get('semantic_model_name', 'Unknown')
                    print(f"      ğŸ“Š {model_name}")
                    metrics = model_data['metrics']
                    if metrics:
                        for metric in metrics:
                            print(f"        â€¢ {metric.get('name', 'Unknown Metric')}")


if __name__ == "__main__":
    # è¯»å–æ•°æ®
    data = read_semantic_models_and_metrics()

    if data:
        # æ˜¾ç¤ºåˆ†å±‚ç»“æ„
        display_hierarchical_structure(data)

        print(f"\næ€»å…±å¤„ç†äº† {len(data)} ä¸ªè¯­ä¹‰æ¨¡å‹")
    else:
        print("æœªè¯»å–åˆ°ä»»ä½•æ•°æ®")
