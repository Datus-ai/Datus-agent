- case: #case_1
  input:
    task_description: |-
{"id": "sf001", "database_type": "snowflake", "task": "Assuming today is April 1, 2025, I would like to know the daily snowfall amounts greater than 6 inches for each U.S. postal code during the week ending after the first two full weeks of the previous year. Show the postal code, date, and snowfall amount.", "database_name": "GLOBAL_WEATHER__CLIMATE_DATA_FOR_BI", "output_dir": "output"}
    sql_generation_result: |-
{"success": true, "error": null, "sql_query": "WITH FIRST_TWO_FULL_WEEKS AS (\n  SELECT DATEADD(DAY, -14, '2025-04-01'::DATE) AS WEEK_END_DATE\n),\nHISTORICAL_SNOWFALL AS (\n  SELECT\n    \"POSTAL_CODE\",\n    \"DATE_VALID_STD\",\n    \"TOT_SNOWFALL_IN\"\n  FROM\n    GLOBAL_WEATHER__CLIMATE_DATA_FOR_BI.STANDARD_TILE.HISTORY_DAY\n  WHERE\n    \"DATE_VALID_STD\" BETWEEN DATEADD(WEEK, -2, (SELECT WEEK_END_DATE FROM FIRST_TWO_FULL_WEEKS)) AND (SELECT WEEK_END_DATE FROM FIRST_TWO_FULL_WEEKS)\n    AND \"TOT_SNOWFALL_IN\" > 6\n    AND \"COUNTRY\" = 'US'\n)\nSELECT\n  \"POSTAL_CODE\",\n  \"DATE_VALID_STD\",\n  \"TOT_SNOWFALL_IN\"\nFROM\n  HISTORICAL_SNOWFALL\nORDER BY\n  \"POSTAL_CODE\",\n  \"DATE_VALID_STD\";", "tables": ["GLOBAL_WEATHER__CLIMATE_DATA_FOR_BI.STANDARD_TILE.HISTORY_DAY"]}
    sql_execution_result: |-
{"success": true, "Error": null, "Rows": 5, "Result": "POSTAL_CODE,DATE_VALID_STD,TOT_SNOWFALL_IN\n  49833,2025-03-05,18.30\n  50040,2025-03-07,6.24\n  96125,2025-03-12,8.11\n  96125,2025-03-14,7.33\n  96125,2025-03-17,7.82"}
  result:
    reflection: "SUCCESS"
- case: #case_2 https://smith.langchain.com/o/71a7222c-85e9-52e0-a083-991688a01ef7/projects/p/914264ff-d719-4fe6-9321-4360193bc879?timeModel=%7B%22duration%22%3A%227d%22%7D&peek=6c5205d7-defe-48cb-ab36-2370e4a6e475
#  input:
#    task_description: Workflow for: id='sf002' database_type='snowflake' task="As of December 31, 2022, list the top 10 active banks with assets exceeding $10 billion, ranked by the highest percentage of uninsured assets, where the percentage is calculated as one minus the value of the '% Insured (Estimated)' variable from quarterly estimates. Provide the names of these banks and their respective percentages of uninsured assets." database_name='FINANCE__ECONOMICS' output_dir='output'
#    sql_generation_result: success=True error=None sql_query='WITH FDIC_SUMMARY_CTE AS ( SELECT "VALUE", "DATE", "FDIC_INSTITUTION_ID", "VARIABLE", "VARIABLE_NAME" FROM "FINANCE__ECONOMICS"."CYBERSYN"."FDIC_SUMMARY_OF_DEPOSITS_TIMESERIES" WHERE "DATE" = \'2022-12-31\' AND "VARIABLE" = \'% Insured (Estimated)\' ), FINANCIAL_INSTITUTION_CTE AS ( SELECT "NAME", "ID_RSSD" FROM "FINANCE__ECONOMICS"."CYBERSYN"."FINANCIAL_INSTITUTION_ENTITIES" WHERE "IS_ACTIVE" = TRUE ), ASSETS_CTE AS ( SELECT "VALUE", "FDIC_INSTITUTION_ID" FROM "FINANCE__ECONOMICS"."CYBERSYN"."FDIC_SUMMARY_OF_DEPOSITS_TIMESERIES" WHERE "DATE" = \'2022-12-31\' AND "VARIABLE" = \'ASSET\' AND "VALUE" > 10000000000 ) SELECT fi."NAME", (1 - fd."VALUE") AS "Uninsured_Assets_Percentage" FROM FDIC_SUMMARY_CTE fd JOIN FINANCIAL_INSTITUTION_CTE fi ON fd."FDIC_INSTITUTION_ID" = fi."ID_RSSD" JOIN ASSETS_CTE a ON fi."ID_RSSD" = a."FDIC_INSTITUTION_ID" ORDER BY "Uninsured_Assets_Percentage" DESC LIMIT 10;' tables=['FDIC_SUMMARY_OF_DEPOSITS_TIMESERIES', 'FINANCIAL_INSTITUTION_ENTITIES'] explanation="To solve this problem, we need to follow these steps: 1. Identify the relevant data from the FDIC_SUMMARY_OF_DEPOSITS_TIMESERIES table for December 31, 2022, specifically for the '% Insured (Estimated)' variable. 2. Retrieve the names and RSSD IDs of active banks from the FINANCIAL_INSTITUTION_ENTITIES table. 3. Filter the banks to include only those with assets exceeding $10 billion by querying the FDIC_SUMMARY_OF_DEPOSITS_TIMESERIES table again for the 'ASSET' variable on the same date. 4. Calculate the percentage of uninsured assets as one minus the '% Insured (Estimated)' value. 5. Join the results from steps 1, 2, and 3 to get the bank names and their respective uninsured asset percentages. 6. Rank the results by the highest percentage of uninsured assets and limit the output to the top 10 banks."
#    sql_execution_result: success:True. Error: None
# Rows: 0
#Result:
#  result:
#    reflection: SCHEMA_LINKING
#- case: #case_3 https://smith.langchain.com/o/71a7222c-85e9-52e0-a083-991688a01ef7/projects/p/914264ff-d719-4fe6-9321-4360193bc879?timeModel=%7B%22duration%22%3A%227d%22%7D&peek=f9ef3b01-71b6-4c9a-8858-b5096ee96c47
#  - input:
#    task_description: 'Workflow for: id='sf002' database_type='snowflake' task="As of December 31, 2022, list the top 10 active banks with assets exceeding $10 billion, ranked by the highest percentage of uninsured assets, where the percentage is calculated as one minus the value of the '% Insured (Estimated)' variable from quarterly estimates. Provide the names of these banks and their respective percentages of uninsured assets." database_name='FINANCE__ECONOMICS' output_dir='output''
#    sql_generation_result: 'success=True error=None sql_query='WITH insured_assets AS (\n    SELECT\n        "FDIC_INSTITUTION_ID",\n        "VALUE" AS insured_percentage\n    FROM\n        FINANCE__ECONOMICS.CYBERSYN.CYBERSYN.FDIC_SUMMARY_OF_DEPOSITS_TIMESERIES\n    WHERE\n        "VARIABLE" = \'% Insured (Estimated)\'\n        AND "DATE" = \'2022-12-31\'\n),\nbank_assets AS (\n    SELECT\n        "FDIC_INSTITUTION_ID",\n        "VALUE" AS total_assets\n    FROM\n        FINANCE__ECONOMICS.CYBERSYN.CYBERSYN.FDIC_SUMMARY_OF_DEPOSITS_TIMESERIES\n    WHERE\n        "VARIABLE" = \'Total Assets\'\n        AND "DATE" = \'2022-12-31\'\n),\nactive_banks AS (\n    SELECT\n        "FDIC_CERT",\n        "NAME"\n    FROM\n        FINANCE__ECONOMICS.CYBERSYN.CYBERSYN.FINANCIAL_INSTITUTION_ENTITIES\n    WHERE\n        "IS_ACTIVE" = TRUE\n)\nSELECT\n    ab."NAME" AS bank_name,\n    ROUND((1 - ia.insured_percentage) * 100, 2) AS uninsured_assets_percentage\nFROM\n    insured_assets ia\nJOIN\n    bank_assets ba ON ia."FDIC_INSTITUTION_ID" = ba."FDIC_INSTITUTION_ID"\nJOIN\n    active_banks ab ON ia."FDIC_INSTITUTION_ID" = ab."FDIC_CERT"\nWHERE\n    ba.total_assets > 10000000000\nORDER BY\n    uninsured_assets_percentage DESC\nLIMIT 10;' tables=['FINANCE__ECONOMICS.CYBERSYN.CYBERSYN.FDIC_SUMMARY_OF_DEPOSITS_TIMESERIES', 'FINANCE__ECONOMICS.CYBERSYN.CYBERSYN.FINANCIAL_INSTITUTION_ENTITIES'] explanation="1. The query first identifies the insured percentage of assets for each bank as of December 31, 2022, by selecting the '% Insured (Estimated)' variable from the FDIC_SUMMARY_OF_DEPOSITS_TIMESERIES table.\n2. Next, it retrieves the total assets for each bank as of the same date from the same table.\n3. It then filters for active banks from the FINANCIAL_INSTITUTION_ENTITIES table.\n4. The query joins these datasets on the FDIC_INSTITUTION_ID and FDIC_CERT fields to match banks with their respective asset and insured percentage data.\n5. It calculates the percentage of uninsured assets as 1 minus the insured percentage, multiplies by 100 to get a percentage, and rounds to two decimal places.\n6. Finally, it filters for banks with total assets exceeding $10 billion, orders the results by the highest percentage of uninsured assets, and limits the output to the top 10 banks."'
#    sql_execution_result: 'Error: errno:2043, sqlstate: 02000, message: 002043 (02000): 01bbb256-0204-f8c8-0001-11c302544962: SQL compilation error:
#Object does not exist, or operation cannot be performed., query_id: 01bbb256-0204-f8c8-0001-11c302544962 
# Rows: 0'
#Result: 
#  result:
#    reflection: SIMPLE_REGENERATE
#    secondary-reflection: SCHEMA_LINKING
#- case: # case_4 https://smith.langchain.com/o/71a7222c-85e9-52e0-a083-991688a01ef7/projects/p/914264ff-d719-4fe6-9321-4360193bc879?timeModel=%7B%22duration%22%3A%227d%22%7D&peek=c58d7123-bb0e-459f-a7c8-80a47bfb09dd reflection_0
#  - input:
#    task_description: 'Workflow for: id='sf003' database_type='snowflake' task='From 2015 to 2020, which zip code in Census Zip Code Tabulation Areas had the second-highest annual population growth rate, given a minimum estimate of 25,000 people over a 5-year period? Include the zip code, state abbreviation, and growth rate.' database_name='GLOBAL_GOVERNMENT' output_dir='output''
#    sql_generation_result: 'success=True error=None sql_query='WITH PopulationData AS ( SELECT "GEO_ID", "VARIABLE", "VARIABLE_NAME", "DATE", "VALUE", "UNIT" FROM "GLOBAL_GOVERNMENT"."CYBERSYN"."AMERICAN_COMMUNITY_SURVEY_TIMESERIES" WHERE "DATE" BETWEEN \'2015-01-01\' AND \'2020-12-31\' AND "UNIT" = \'Count\' ), ZipCodePopulation AS ( SELECT "GEO_ID", YEAR("DATE") AS "YEAR", AVG("VALUE") AS "AVG_POPULATION" FROM PopulationData GROUP BY "GEO_ID", YEAR("DATE") ), AnnualGrowthRate AS ( SELECT "GEO_ID", (MAX("AVG_POPULATION") - MIN("AVG_POPULATION")) / MIN("AVG_POPULATION") * 100 AS "GROWTH_RATE" FROM ZipCodePopulation GROUP BY "GEO_ID" HAVING MAX("AVG_POPULATION") >= 25000 ), RankedGrowth AS ( SELECT "GEO_ID", "GROWTH_RATE", RANK() OVER (ORDER BY "GROWTH_RATE" DESC) AS "RANK" FROM AnnualGrowthRate ), GeographyInfo AS ( SELECT "GEO_ID", "GEO_NAME", "ISO_ALPHA2" FROM "GLOBAL_GOVERNMENT"."CYBERSYN"."GEOGRAPHY_INDEX" WHERE "LEVEL" = \'CensusZipCodeTabulationArea\' ) SELECT "GEO_ID", "GEO_NAME", "ISO_ALPHA2", "GROWTH_RATE" FROM RankedGrowth rg JOIN GeographyInfo gi ON rg."GEO_ID" = gi."GEO_ID" WHERE "RANK" = 2;' tables=['AMERICAN_COMMUNITY_SURVEY_TIMESERIES', 'GEOGRAPHY_INDEX'] explanation="Step 1: Extract population data from 2015 to 2020 where the unit is 'Count'. Step 2: Calculate the average population for each year per GEO_ID. Step 3: Compute the annual growth rate for each GEO_ID, ensuring the maximum population is at least 25,000. Step 4: Rank the growth rates in descending order. Step 5: Fetch geographic information for Census Zip Code Tabulation Areas. Step 6: Join the ranked growth data with geographic information to find the zip code with the second-highest growth rate, including the zip code, state abbreviation, and growth rate."'
#    sql_execution_result: 'Error: errno:2028, sqlstate: 42601, message: 002028 (42601): 01bbb279-0204-f8c8-0001-11c302544a22: SQL compilation error:
#ambiguous column name 'GEO_ID', query_id: 01bbb279-0204-f8c8-0001-11c302544a22
# Rows: 0
#Result: '
#  result:
#    reflection: SIMPLE_REGENERATE
#- case: # case_5 https://smith.langchain.com/o/71a7222c-85e9-52e0-a083-991688a01ef7/projects/p/914264ff-d719-4fe6-9321-4360193bc879?timeModel=%7B%22duration%22%3A%227d%22%7D&peek=c58d7123-bb0e-459f-a7c8-80a47bfb09dd reflection_1
#  - input:
#    task_description: 'Workflow for: id='sf003' database_type='snowflake' task='From 2015 to 2020, which zip code in Census Zip Code Tabulation Areas had the second-highest annual population growth rate, given a minimum estimate of 25,000 people over a 5-year period? Include the zip code, state abbreviation, and growth rate.' database_name='GLOBAL_GOVERNMENT' output_dir='output''
#    sql_generation_result: 'success=True error=None sql_query='WITH PopulationData AS ( SELECT "GEO_ID", "VARIABLE", "VARIABLE_NAME", "DATE", "VALUE", "UNIT" FROM "GLOBAL_GOVERNMENT"."CYBERSYN"."AMERICAN_COMMUNITY_SURVEY_TIMESERIES" WHERE "DATE" BETWEEN \'2015-01-01\' AND \'2020-12-31\' AND "UNIT" = \'Count\' ), ZipCodePopulation AS ( SELECT "GEO_ID", YEAR("DATE") AS "YEAR", AVG("VALUE") AS "AVG_POPULATION" FROM PopulationData GROUP BY "GEO_ID", YEAR("DATE") ), AnnualGrowthRate AS ( SELECT "GEO_ID", (MAX("AVG_POPULATION") - MIN("AVG_POPULATION")) / MIN("AVG_POPULATION") * 100 AS "GROWTH_RATE" FROM ZipCodePopulation GROUP BY "GEO_ID" HAVING MAX("AVG_POPULATION") >= 25000 ), RankedGrowth AS ( SELECT "GEO_ID", "GROWTH_RATE", RANK() OVER (ORDER BY "GROWTH_RATE" DESC) AS "RANK" FROM AnnualGrowthRate ), GeographyInfo AS ( SELECT "GEO_ID", "GEO_NAME", "ISO_ALPHA2" FROM "GLOBAL_GOVERNMENT"."CYBERSYN"."GEOGRAPHY_INDEX" WHERE "LEVEL" = \'CensusZipCodeTabulationArea\' ) SELECT rg."GEO_ID", gi."GEO_NAME", gi."ISO_ALPHA2", rg."GROWTH_RATE" FROM RankedGrowth rg JOIN GeographyInfo gi ON rg."GEO_ID" = gi."GEO_ID" WHERE rg."RANK" = 2;' tables=['GLOBAL_GOVERNMENT.CYBERSYN.AMERICAN_COMMUNITY_SURVEY_TIMESERIES', 'GLOBAL_GOVERNMENT.CYBERSYN.GEOGRAPHY_INDEX'] explanation='The query is designed to find the zip code in Census Zip Code Tabulation Areas with the second-highest annual population growth rate from 2015 to 2020, given a minimum population estimate of 25,000 people over the 5-year period. The query is broken down into several steps: 1. Filter the population data for the specified period and unit type. 2. Calculate the average population for each year and zip code. 3. Compute the annual growth rate for each zip code, ensuring the minimum population threshold is met. 4. Rank the zip codes by their growth rate. 5. Retrieve the geography information for the zip codes. 6. Select the zip code with the second-highest growth rate, including the zip code, state abbreviation, and growth rate.''
#    sql_execution_result: 'success:True. Error: errno:630, sqlstate: 57014, message: 000630 (57014): None: Statement reached its statement or warehouse timeout of 200 second(s) and was canceled., query_id: None'
#  result:
#    reflection: COMPLEX_REASONING
#- case: #case_6
#    task_description: Workflow for: 'id='sf_bq104' database_type='snowflake' task='Based on the most recent refresh date, identify the top-ranked rising search term for the week that is exactly one year prior to the latest available week in the dataset.' database_name='GOOGLE_TRENDS' output_dir='output''
#    sql_generation_result: 'success=True error=None sql_query='WITH LatestWeek AS ( SELECT MAX("week") AS latest_week FROM GOOGLE_TRENDS.GOOGLE_TRENDS.TOP_RISING_TERMS ), OneYearPriorWeek AS ( SELECT DATEADD(year, -1, latest_week) AS one_year_prior_week FROM LatestWeek ), TopRankedTerm AS ( SELECT "term", "week", "rank" FROM GOOGLE_TRENDS.GOOGLE_TRENDS.TOP_RISING_TERMS WHERE "week" = (SELECT one_year_prior_week FROM OneYearPriorWeek) ORDER BY "rank" ASC LIMIT 1 ) SELECT "term", "week", "rank" FROM TopRankedTerm;' tables=['GOOGLE_TRENDS.GOOGLE_TRENDS.TOP_RISING_TERMS'] explanation='1. First, we identify the latest available week in the dataset using a Common Table Expression (CTE) named LatestWeek. 2. Next, we calculate the week that is exactly one year prior to the latest week using another CTE named OneYearPriorWeek. 3. Finally, we fetch the top-ranked rising search term for that specific week from the TOP_RISING_TERMS table, ordering by rank in ascending order and limiting the result to 1 to get the top-ranked term.''
#    sql_execution_result: 'Error: None
#Rows: 0
#Result: '
#  result:
#    reflection: COLUMN_EXPLORATION
#- case: #case_7
#  input:
#    task_description: 'Task description: Workflow for: id='sf_bq012' database_type='snowflake' task='Calculate the average balance (in quadrillions, 10^15) of the top 10 Ethereum addresses by net balance, including incoming and outgoing transfers from traces (only successful transactions and excluding call types like delegatecall, callcode, and staticcall), miner rewards (sum of gas fees per block), and sender gas fee deductions. Exclude null addresses and round the result to two decimal places.' database_name='ETHEREUM_BLOCKCHAIN' output_dir='output''
#    sql_generation_result: 'Generated SQL: success=True error=None sql_query='WITH successful_traces AS ( SELECT "from_address" AS "address", -"value" AS "balance_change" FROM ETHEREUM_BLOCKCHAIN.ETHEREUM_BLOCKCHAIN.TRACES WHERE "status" = 1 AND "call_type" NOT IN (\'delegatecall\', \'callcode\', \'staticcall\') UNION ALL SELECT "to_address" AS "address", "value" AS "balance_change" FROM ETHEREUM_BLOCKCHAIN.ETHEREUM_BLOCKCHAIN.TRACES WHERE "status" = 1 AND "call_type" NOT IN (\'delegatecall\', \'callcode\', \'staticcall\') ), miner_rewards AS ( SELECT "miner" AS "address", SUM("gas_used" * "gas_price") / POWER(10, 18) AS "miner_reward" FROM ETHEREUM_BLOCKCHAIN.ETHEREUM_BLOCKCHAIN.TRANSACTIONS t JOIN ETHEREUM_BLOCKCHAIN.ETHEREUM_BLOCKCHAIN.BLOCKS b ON t."block_number" = b."number" GROUP BY "miner" ), sender_gas_fees AS ( SELECT "from_address" AS "address", -SUM("gas_used" * "gas_price") / POWER(10, 18) AS "gas_fee" FROM ETHEREUM_BLOCKCHAIN.ETHEREUM_BLOCKCHAIN.TRANSACTIONS WHERE "receipt_status" = 1 GROUP BY "from_address" ), combined_balances AS ( SELECT "address", SUM("balance_change") / POWER(10, 15) AS "net_balance" FROM successful_traces GROUP BY "address" UNION ALL SELECT "address", "miner_reward" / POWER(10, 15) AS "net_balance" FROM miner_rewards UNION ALL SELECT "address", "gas_fee" / POWER(10, 15) AS "net_balance" FROM sender_gas_fees ), top_addresses AS ( SELECT "address", SUM("net_balance") AS "total_net_balance" FROM combined_balances WHERE "address" IS NOT NULL GROUP BY "address" ORDER BY "total_net_balance" DESC LIMIT 10 ) SELECT ROUND(AVG("total_net_balance"), 2) AS "average_balance" FROM top_addresses;' tables=['TRACES', 'TRANSACTIONS', 'BLOCKS'] explanation='The query is broken down into several steps: 1. Extract successful traces excluding specific call types and calculate balance changes. 2. Calculate miner rewards by summing gas fees per block. 3. Calculate sender gas fees by summing gas fees for successful transactions. 4. Combine the results from the above steps and convert the balance to quadrillions. 5. Identify the top 10 addresses by net balance. 6. Calculate the average balance of these top 10 addresses and round it to two decimal places.''
#    sql_execution_result: 'Execution results: Error: errno:904, sqlstate: 42000, message: 000904 (42000): 01bbb34d-0204-fa26-0001-11c302549cf2: SQL compilation error: error line 1 at position 783
#invalid identifier '"gas_used"', query_id: 01bbb34d-0204-fa26-0001-11c302549cf2
#Rows: 0
#Result: '
#  result:
#    reflection: SIMPLE_REGENERATE
##  - case_7
##    task_description:
##    sql_generation_result:
##    sql_execution_result:
##  result:
##    reflection: SCHEMA_LINKING
##    
##  - case_8
##    task_description:
##    sql_generation_result:
##    sql_execution_result:
##    reflection: SCHEMA_LINKING
##    
##  - case_9
##    task_description:
##    sql_generation_result:
##    sql_execution_result:
##    reflection: SCHEMA_LINKING
##    
##  - case_10
##    task_description:
##    sql_generation_result:
##    sql_execution_result:
##    reflection: SCHEMA_LINKING
##
